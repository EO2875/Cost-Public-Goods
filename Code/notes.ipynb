{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood\n",
    "\n",
    "Both [Statlect](https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood)\n",
    "and ChatGPT state that the log-likelihood funciton of a linear model is:\n",
    "\n",
    "$$ l = \n",
    "    - \\frac{N}{2} \\ln(2\\pi) \n",
    "    - \\frac{N}{2} \\ln(\\sigma^2) \n",
    "    - \\frac{1}{2\\sigma^2} \\sum^N_{i=1} (y_i - \\hat{\\beta} x_i) ^2 \n",
    "$$\n",
    "\n",
    "It seems to be derived from the fact that a model \n",
    "    $ Y = \\beta_0 + \\beta_1 X + \\varepsilon$\n",
    "is normally distributed as $N(\\beta_0 + \\beta_1 X, \\sigma^2) $. \n",
    "The distribution function of $Y$ is thus:\n",
    "\n",
    "$$ f_Y(x) = \n",
    "    \\frac{1}{\\sigma\\sqrt{2\\pi}} \n",
    "    e^{-\\frac{1}{2}\\left(\\frac{x - \\mu}{\\sigma}\\right)^2}\n",
    "    = (2\\pi\\sigma^2)^{-\\frac{1}{2}}\n",
    "    e^{-\\frac{1}{2 \\sigma^2}\\left(x - \\mu\\right)^2}\n",
    "$$\n",
    "\n",
    "Why is the left side being raised to the power of $N$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to BDM's code, AIC is computed as:\n",
    "\n",
    "$$ k = df_m +df_1 + 1 $$ \n",
    "\n",
    "$$  AIC = -2 l \n",
    "    + 2( df_m +df_1 + 1 ) \n",
    "    + 2 \\frac{( df_m +df_1 + 1 ) ( e(df_m)+e(df_a)+2 )}{(e(N)-(e(df_m)+e(df_a)+1)-1}\n",
    "$$\n",
    "\n",
    "$$  = -2 l + 2 k + 2 \\frac{k (k+1)}{N-k-1}\n",
    "    = AICc\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustered Standard Error\n",
    "\n",
    "$$ \\text{SE}(\\hat{\\beta_1}) = \\sqrt{\\frac{1}{nT} \\frac{s_\\eta^2}{\\hat{Q}_X^2}} $$\n",
    "\n",
    "$$ s_\\eta^2 = \\frac{1}{N-1} \\sum_{i=1}^n(\\hat{\\eta}_i-\\bar{\\hat{\\eta}})^2 $$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
